{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "488f3f66d3f74566867b9b8040ddd351": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_420edf95bbfe415eafc9cadde6c34b3f",
              "IPY_MODEL_ef5cb151c63d40859a6e96f7583a50de",
              "IPY_MODEL_774a421d0b9d4b52a24a59678d6b6359"
            ],
            "layout": "IPY_MODEL_62992d4d917c48dcad10506586a18935"
          }
        },
        "420edf95bbfe415eafc9cadde6c34b3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c00b6b18e73455088f23f4ddf1d0f59",
            "placeholder": "​",
            "style": "IPY_MODEL_9d3b302f64434f2f9d12b65e8e725441",
            "value": "Pandas Apply: 100%"
          }
        },
        "ef5cb151c63d40859a6e96f7583a50de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47583c280bc240c19908cae5034cbc36",
            "max": 352151,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_62fdde691ce744fbb4cf52e41bd51372",
            "value": 352151
          }
        },
        "774a421d0b9d4b52a24a59678d6b6359": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7716587ac4db4d51acee63ddf09bafd7",
            "placeholder": "​",
            "style": "IPY_MODEL_7cbc87594d4d48f8a6a50491a3368cf9",
            "value": " 352151/352151 [00:09&lt;00:00, 40453.00it/s]"
          }
        },
        "62992d4d917c48dcad10506586a18935": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c00b6b18e73455088f23f4ddf1d0f59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d3b302f64434f2f9d12b65e8e725441": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47583c280bc240c19908cae5034cbc36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62fdde691ce744fbb4cf52e41bd51372": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7716587ac4db4d51acee63ddf09bafd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cbc87594d4d48f8a6a50491a3368cf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNv0VWXIRGyd",
        "outputId": "85f874a9-d669-4faf-db40-936c8738d14e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using: cuda\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import regex as re\n",
        "import warnings\n",
        "import swifter\n",
        "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
        "from tokenizers import Tokenizer, models, pre_tokenizers, trainers\n",
        "\n",
        "\n",
        "# PARAMETERS OF MODEL\n",
        "block_size = 128\n",
        "batch_size = 64\n",
        "vocab_size = 30_000\n",
        "n_embd = 128\n",
        "n_head = 4\n",
        "n_layer = 4\n",
        "dropout = 0.2\n",
        "learning_rate = 3e-4\n",
        "max_iter = 5\n",
        "n_classes = 3\n",
        "\n",
        "\n",
        "# TRAINING\n",
        "train_size = 315704\n",
        "val_size = 35079\n",
        "\n",
        "# PADDING\n",
        "pad_token = '<pad>'\n",
        "unk_token = \"<unk>\"\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using:\", device)\n",
        "\n",
        "\n",
        "\n",
        "# DATA NORMALIZATION\n",
        "def get_normalized_customer_reviews():\n",
        "    uzum_df = pd.read_parquet(\"./uzum_dataset.parquet\", engine='pyarrow')\n",
        "    rating_map = {\n",
        "    'poor' : 0,\n",
        "    'very poor' : 0,\n",
        "    'fair' : 1,\n",
        "    'good' : 2,\n",
        "    'excellent' : 2\n",
        "    }\n",
        "\n",
        "    uzum_df[\"rank\"] = uzum_df[\"rating\"].map(rating_map)\n",
        "    uzum_df.drop('rating', axis=1, inplace=True)\n",
        "\n",
        "    latin = r\"\\p{Latin}\"\n",
        "    cyrillic = r\"\\p{Cyrillic}\"\n",
        "    digits = r\"\\p{Number}\"\n",
        "\n",
        "\n",
        "    allowed_re = re.compile(fr\"(?:{latin}|{cyrillic}|{digits}|\\s)\")\n",
        "\n",
        "    final_clean = {'ø','ʔ','ʕ','ʖ','ᴥ','ᵕ','⅚','ᴗ'}\n",
        "\n",
        "    latin_map = {\n",
        "    \"à\": \"a\", \"á\": \"a\", \"â\": \"a\", \"ã\": \"a\",\n",
        "    \"ç\": \"c\",\n",
        "    \"è\": \"e\", \"é\": \"e\", \"ë\": \"e\",\n",
        "    \"ì\": \"i\", \"í\": \"i\",\n",
        "    \"ñ\": \"n\",\n",
        "    \"ò\": \"o\", \"ó\": \"o\", \"ô\": \"o\", \"õ\": \"o\", \"ö\": \"o\",\n",
        "    \"ù\": \"u\", \"ú\": \"u\", \"û\": \"u\", \"ü\": \"u\",\n",
        "    \"ý\": \"y\", \"ÿ\": \"y\",\n",
        "    \"ĝ\": \"g'\", \"ğ\": \"g'\", \"ġ\": \"g'\", \"ģ\": \"g'\",\n",
        "    \"ĥ\": \"h\",\n",
        "    \"ı\": \"i\",\n",
        "    \"ĵ\": \"j\",\n",
        "    \"ķ\": \"k\",\n",
        "    \"ĺ\": \"l\", \"ļ\": \"l\",\n",
        "    \"ń\": \"n\", \"ň\": \"n\",\n",
        "    \"ō\": \"o'\", \"ŏ\": \"o'\", \"ő\": \"o'\",\n",
        "    \"ŕ\": \"r\",\n",
        "    \"ś\": \"s\", \"ş\": \"sh\",\n",
        "    \"ũ\": \"u\", \"ū\": \"u\", \"ů\": \"u\",\n",
        "    \"ź\": \"z\", \"ž\": \"j\",\n",
        "    \"ǒ\": \"o'\", \"ǫ\": \"q\",\n",
        "    \"ǵ\": \"g'\",\n",
        "    \"ɓ\": \"b\",\n",
        "    \"ə\": \"e\",\n",
        "    '²': '2',\n",
        "    '³': '3',\n",
        "    '¹': '1',\n",
        "    'ď': 'd',\n",
        "    'ɢ': 'g',\n",
        "    'ɪ': 'i',\n",
        "    'ɴ': 'n',\n",
        "    'ʀ': 'r',\n",
        "    'ʏ': 'y',\n",
        "    'ʜ': 'h',\n",
        "    'ʟ': 'l',\n",
        "    'ө': 'o',\n",
        "    'ᴀ': 'a',\n",
        "    'ᴄ': 'c',\n",
        "    'ᴅ': 'd',\n",
        "    'ᴇ': 'e',\n",
        "    'ᴊ': 'j',\n",
        "    'ᴋ': 'k',\n",
        "    'ᴍ': 'm',\n",
        "    'ᴏ': 'o',\n",
        "    'ᴘ': 'p',\n",
        "    'ᴛ': 't',\n",
        "    'ᴜ': 'u',\n",
        "    '⁰': '0',\n",
        "    '⁴': '4',\n",
        "    '⁵': '5'\n",
        "}\n",
        "\n",
        "\n",
        "    def normalize_text(text: str) -> str:\n",
        "        out = []\n",
        "        for ch in text:\n",
        "            # skips unnessary ones\n",
        "            if ch in final_clean:\n",
        "               continue\n",
        "\n",
        "            # keeps only necessary chars\n",
        "            if not allowed_re.fullmatch(ch):\n",
        "               continue\n",
        "\n",
        "            # maps final\n",
        "            out.append(latin_map.get(ch, ch))\n",
        "\n",
        "        return \"\".join(out)\n",
        "\n",
        "    uzum_df[\"review_text\"] = uzum_df[\"normalized_review_text\"].astype(str).swifter.apply(normalize_text)\n",
        "    uzum_df['len'] = uzum_df['review_text'].astype(str).str.len()\n",
        "    uzum_df = uzum_df[uzum_df['len'] > 0].drop(['len', 'normalized_review_text'], axis=1)[['review_text', 'rank']]\n",
        "\n",
        "    return uzum_df\n",
        "\n",
        "\n",
        "\n",
        "def get_tokenized_data():\n",
        "\n",
        "  df = get_normalized_customer_reviews()\n",
        "\n",
        "  tokenizer = Tokenizer(models.BPE())\n",
        "  tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()\n",
        "\n",
        "\n",
        "  trainer = trainers.BpeTrainer(\n",
        "        vocab_size=vocab_size,\n",
        "        special_tokens=[pad_token, unk_token]\n",
        "    )\n",
        "\n",
        "  tokenizer.train_from_iterator(df[\"review_text\"].astype(str).tolist(), trainer)\n",
        "\n",
        "  PAD_ID = tokenizer.token_to_id(pad_token)\n",
        "  UNK_ID = tokenizer.token_to_id(unk_token)\n",
        "\n",
        "  def encode_and_padding(text):\n",
        "    ids = tokenizer.encode(text).ids[:block_size]\n",
        "    ids += [PAD_ID] * (block_size - len(ids))\n",
        "    return ids\n",
        "\n",
        "\n",
        "  X_padded = [encode_and_padding(t) for t in df[\"review_text\"]]\n",
        "\n",
        "  data = torch.tensor(X_padded, dtype=torch.long)\n",
        "  targets = torch.tensor(df['rank'].values, dtype=torch.long)\n",
        "\n",
        "  return data, targets, tokenizer\n",
        "\n",
        "\n",
        "\n",
        "# TRANSFORMER MODEL\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "\n",
        "        k = self.key(x)           # (B,T,hs)\n",
        "        q = self.query(x)         # (B,T,hs)\n",
        "\n",
        "        wei = q @ k.transpose(-2, -1) * (k.size(-1)**-0.5)\n",
        "        wei = F.softmax(wei, dim=-1)\n",
        "        wei = self.dropout(wei)\n",
        "\n",
        "        v = self.value(x)\n",
        "        out = wei @ v\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList(SelfAttention(head_size) for _ in range(num_heads))\n",
        "        self.proj = nn.Linear(n_embd, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4*n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffw = FeedForward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        x = x + self.ffw(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "class EncoderTransformerClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd)\n",
        "        self.classifier = nn.Linear(n_embd, n_classes)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        idx = idx.to(self.token_embedding_table.weight.device)\n",
        "        B, T = idx.shape\n",
        "\n",
        "        tok_emb = self.token_embedding_table(idx)\n",
        "        pos = torch.arange(T, device=idx.device)\n",
        "        pos_emb = self.position_embedding_table(pos)\n",
        "        x = tok_emb + pos_emb\n",
        "\n",
        "        x = self.blocks(x)\n",
        "        x = self.ln_f(x)\n",
        "        lengths = (idx != 0).sum(dim=1) - 1\n",
        "        x_cls = x[torch.arange(B), lengths]\n",
        "\n",
        "        logits = self.classifier(x_cls)\n",
        "\n",
        "        if targets is None:\n",
        "            return logits\n",
        "\n",
        "        loss = F.cross_entropy(logits, targets)\n",
        "        return logits, loss\n",
        "\n",
        "\n",
        "    def predict(self, text, tokenizer):\n",
        "        self.eval()\n",
        "\n",
        "        ids = tokenizer.encode(text).ids\n",
        "        if len(ids) < block_size:\n",
        "            ids += [0] * (block_size - len(ids))\n",
        "        ids = ids[:block_size]\n",
        "\n",
        "        x = torch.tensor([ids], dtype=torch.long)\n",
        "        x = x.to(next(self.parameters()).device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = self(x)\n",
        "            probs = F.softmax(logits, dim=1)\n",
        "\n",
        "        return probs.cpu().numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# getting data in proper format\n",
        "data, targets, tokenizer = get_tokenized_data()\n",
        "\n",
        "\n",
        "dataset = TensorDataset(data, targets)\n",
        "train_data, val_data = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "val_loader   = DataLoader(val_data, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "488f3f66d3f74566867b9b8040ddd351",
            "420edf95bbfe415eafc9cadde6c34b3f",
            "ef5cb151c63d40859a6e96f7583a50de",
            "774a421d0b9d4b52a24a59678d6b6359",
            "62992d4d917c48dcad10506586a18935",
            "5c00b6b18e73455088f23f4ddf1d0f59",
            "9d3b302f64434f2f9d12b65e8e725441",
            "47583c280bc240c19908cae5034cbc36",
            "62fdde691ce744fbb4cf52e41bd51372",
            "7716587ac4db4d51acee63ddf09bafd7",
            "7cbc87594d4d48f8a6a50491a3368cf9"
          ]
        },
        "id": "CFHuWgF6RTP-",
        "outputId": "ba32c86b-2a4d-45cf-bdc0-bc6931ac656b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Pandas Apply:   0%|          | 0/352151 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "488f3f66d3f74566867b9b8040ddd351"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# building the model\n",
        "model = EncoderTransformerClassifier().to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "YpVSUs-KRUv0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "for epoch in range(max_iter):\n",
        "\n",
        "    # train\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "\n",
        "    for xb, yb in train_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits, loss = model(xb, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    train_loss /= len(train_loader)\n",
        "\n",
        "    # validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in val_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "\n",
        "            logits, loss = model(xb, yb)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            preds = logits.argmax(dim=1)\n",
        "            correct += (preds == yb).sum().item()\n",
        "            total += yb.size(0)\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "    val_acc = correct / total\n",
        "\n",
        "    print(f\"epoch [{epoch+1}/{max_iter}] \"\n",
        "      f\"train loss: {train_loss:.4f} \"\n",
        "      f\"val loss: {val_loss:.4f} \"\n",
        "      f\"val acc: {val_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRbssYgNRt7_",
        "outputId": "c464bd57-0dd2-42e5-ba7e-226f2dd4c5b0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch [1/5] train loss: 0.3809 val loss: 0.3340 val acc: 0.8870\n",
            "epoch [2/5] train loss: 0.3226 val loss: 0.3225 val acc: 0.8915\n",
            "epoch [3/5] train loss: 0.3035 val loss: 0.3185 val acc: 0.8972\n",
            "epoch [4/5] train loss: 0.2904 val loss: 0.3058 val acc: 0.9000\n",
            "epoch [5/5] train loss: 0.2788 val loss: 0.3144 val acc: 0.8983\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SAVING MODEL AND TOKENIZER\n",
        "torch.save(model.state_dict(), \"encoder_transformer_classifier.pth\")\n",
        "tokenizer.save(\"tokenizer.json\")"
      ],
      "metadata": {
        "id": "OXrk-B76aNWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testing 1\n",
        "text = \"oyimga ko'rsattim bo'larkan, yoqmasa kerak deb o'ylagandim\"\n",
        "probs = model.predict(text, tokenizer)[0].tolist()\n",
        "out = np.argmax(probs)\n",
        "print(probs)\n",
        "print('postive' if out == 2 else 'neutral' if out == 1 else 'negative')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hcpc48bGaO2b",
        "outputId": "41729fd8-a4f4-476f-fd1f-46e00542ec02"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.05627254769206047, 0.10021945834159851, 0.8435080051422119]\n",
            "postive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# testing 2\n",
        "text2 = \"oyimga ko'rsattim bo'larkan, yoqmasa kerak deb o'ylagandim, lekin o'zimga to'grisi vashe ishlashi yoqmadi\"\n",
        "probs2 = model.predict(text2, tokenizer)[0].tolist()\n",
        "out2 = np.argmax(probs2)\n",
        "print(probs2)\n",
        "print('postive' if out2 == 2 else 'neutral' if out2 == 1 else 'negative')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NdqjaabaSa0",
        "outputId": "8e2fa442-1489-48bd-fb47-074371c0c6ad"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.8249456286430359, 0.06274730712175369, 0.11230713129043579]\n",
            "negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# testing 3\n",
        "text3 = \"telefon boshida yaxsh ishladi, keyin o'zidan o'zi ekrani ishlamiy qoldi\"\n",
        "probs3 = model.predict(text3, tokenizer)[0].tolist()\n",
        "out3 = np.argmax(probs3)\n",
        "print(probs3)\n",
        "print('postive' if out3 == 2 else 'neutral' if out3 == 1 else 'negative')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hfwb13HOaTA1",
        "outputId": "e4774f79-ace2-4b05-b2c0-35472a0d4561"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.8518344163894653, 0.10748768597841263, 0.04067792743444443]\n",
            "negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# testing 4\n",
        "text3 = \"sotuvchiga bog'lanib bomayapti, texnikasi yaxsh chiqmadi\"\n",
        "probs3 = model.predict(text3, tokenizer)[0].tolist()\n",
        "out3 = np.argmax(probs3)\n",
        "print(probs3)\n",
        "print('postive' if out3 == 2 else 'neutral' if out3 == 1 else 'negative')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdxgIGTNb9df",
        "outputId": "cf0144ab-5bb4-42b8-dade-c6aeaf1d8a89"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.7627807855606079, 0.1507342904806137, 0.08648484200239182]\n",
            "negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# testing 5\n",
        "text3 = \"boshida yaxsh ishladi, keyin buzilib qoldi\"\n",
        "probs3 = model.predict(text3, tokenizer)[0].tolist()\n",
        "out3 = np.argmax(probs3)\n",
        "print(probs3)\n",
        "print('postive' if out3 == 2 else 'neutral' if out3 == 1 else 'negative')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FllEjF0cctT7",
        "outputId": "e389aa81-e68e-4f93-f59a-70514f0e8285"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.7644281387329102, 0.13835835456848145, 0.09721344709396362]\n",
            "negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SAVING MODEL AND TOKENIZER\n",
        "torch.save(model.state_dict(), \"encoder_transformer_classifier.pth\")\n",
        "tokenizer.save(\"tokenizer.json\")"
      ],
      "metadata": {
        "id": "QR76W6WnbbRV"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_module_params(module):\n",
        "    return sum(p.numel() for p in module.parameters() if p.requires_grad)\n",
        "\n",
        "embedding_params = count_module_params(model.token_embedding_table)\n",
        "pos_embedding_params = count_module_params(model.position_embedding_table)\n",
        "classifier_params = count_module_params(model.classifier)\n",
        "\n",
        "attn_params = 0\n",
        "ffw_params = 0\n",
        "for block in model.blocks:\n",
        "    attn_params += count_module_params(block.sa)\n",
        "    ffw_params += count_module_params(block.ffw)\n",
        "\n",
        "print(f\"Embedding layer: {embedding_params}\")\n",
        "print(f\"Positional embedding: {pos_embedding_params}\")\n",
        "print(f\"Attention projections: {attn_params}\")\n",
        "print(f\"Feed-forward block: {ffw_params}\")\n",
        "print(f\"Classifier: {classifier_params}\")\n",
        "\n",
        "print(f\"Total trainable parameters: {embedding_params + pos_embedding_params + attn_params + ffw_params + classifier_params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pltyvJrtbeqv",
        "outputId": "ad0815ec-2eff-41bb-b39c-80a5868ff9e6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding layer: 3840000\n",
            "Positional embedding: 16384\n",
            "Attention projections: 262656\n",
            "Feed-forward block: 526848\n",
            "Classifier: 387\n",
            "Total trainable parameters: 4646275\n"
          ]
        }
      ]
    }
  ]
}