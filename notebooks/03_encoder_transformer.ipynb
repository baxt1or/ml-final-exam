{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "PxuNaCj9Gkb0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from tokenizers import Tokenizer, models, pre_tokenizers, trainers\n",
        "import regex as re\n",
        "import warnings\n",
        "import swifter\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "uDMzj4v5GqD7"
      },
      "outputs": [],
      "source": [
        "vocab_size=30000\n",
        "\n",
        "batch_size = 64\n",
        "block_size = 80 # number of tokens in one sentence\n",
        "learning_rate = 3e-3\n",
        "\n",
        "max_iter = 10\n",
        "\n",
        "n_embd = 64\n",
        "n_head = 4\n",
        "n_layer = 4\n",
        "dropout = 0.2\n",
        "\n",
        "\n",
        "text_column = \"clean_text\"\n",
        "target_column = \"rnk\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSoGhm2YGqqe"
      },
      "outputs": [],
      "source": [
        "uzum_reviews_df = pd.read_parquet(\"./data/uzum_dataset.parquet\", engine='pyarrow')\n",
        "uzum_reviews_df[\"len\"] = uzum_reviews_df[\"normalized_review_text\"].str.len()\n",
        "uzum_reviews_filtered_df = uzum_reviews_df[uzum_reviews_df[\"len\"] <= block_size]\n",
        "rating_map = {\n",
        "    'very poor' : 0,\n",
        "    'poor' : 0,\n",
        "    'fair' : 1,\n",
        "    'good' : 2,\n",
        "    'excellent' : 2\n",
        "}\n",
        "\n",
        "uzum_reviews_filtered_df[\"rnk\"] = uzum_reviews_filtered_df[\"rating\"].map(rating_map)\n",
        "\n",
        "\n",
        "def normalize_uzum_reviews(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    cleans the text based on the following criterias listed below\n",
        "    :param df: pandas dataframe\n",
        "    :returns: cleaned pandas dataframe\n",
        "    \"\"\"\n",
        "\n",
        "    latin = r\"\\p{Latin}\"\n",
        "    cyrillic = r\"\\p{Cyrillic}\"\n",
        "    digits = r\"\\p{Number}\"\n",
        "\n",
        "\n",
        "    allowed_re = re.compile(fr\"(?:{latin}|{cyrillic}|{digits}|\\s)\")\n",
        "\n",
        "    final_clean = {'ø','ʔ','ʕ','ʖ','ᴥ','ᵕ','⅚','ᴗ'}\n",
        "\n",
        "    latin_map = {\n",
        "    \"à\": \"a\", \"á\": \"a\", \"â\": \"a\", \"ã\": \"a\",\n",
        "    \"ç\": \"c\",\n",
        "    \"è\": \"e\", \"é\": \"e\", \"ë\": \"e\",\n",
        "    \"ì\": \"i\", \"í\": \"i\",\n",
        "    \"ñ\": \"n\",\n",
        "    \"ò\": \"o\", \"ó\": \"o\", \"ô\": \"o\", \"õ\": \"o\", \"ö\": \"o\",\n",
        "    \"ù\": \"u\", \"ú\": \"u\", \"û\": \"u\", \"ü\": \"u\",\n",
        "    \"ý\": \"y\", \"ÿ\": \"y\",\n",
        "    \"ĝ\": \"g'\", \"ğ\": \"g'\", \"ġ\": \"g'\", \"ģ\": \"g'\",\n",
        "    \"ĥ\": \"h\",\n",
        "    \"ı\": \"i\",\n",
        "    \"ĵ\": \"j\",\n",
        "    \"ķ\": \"k\",\n",
        "    \"ĺ\": \"l\", \"ļ\": \"l\",\n",
        "    \"ń\": \"n\", \"ň\": \"n\",\n",
        "    \"ō\": \"o'\", \"ŏ\": \"o'\", \"ő\": \"o'\",\n",
        "    \"ŕ\": \"r\",\n",
        "    \"ś\": \"s\", \"ş\": \"sh\",\n",
        "    \"ũ\": \"u\", \"ū\": \"u\", \"ů\": \"u\",\n",
        "    \"ź\": \"z\", \"ž\": \"j\",\n",
        "    \"ǒ\": \"o'\", \"ǫ\": \"q\",\n",
        "    \"ǵ\": \"g'\",\n",
        "    \"ɓ\": \"b\",\n",
        "    \"ə\": \"e\",\n",
        "    '²': '2',\n",
        "    '³': '3',\n",
        "    '¹': '1',\n",
        "    'ď': 'd',\n",
        "    'ɢ': 'g',\n",
        "    'ɪ': 'i',\n",
        "    'ɴ': 'n',\n",
        "    'ʀ': 'r',\n",
        "    'ʏ': 'y',\n",
        "    'ʜ': 'h',\n",
        "    'ʟ': 'l',\n",
        "    'ө': 'o',\n",
        "    'ᴀ': 'a',\n",
        "    'ᴄ': 'c',\n",
        "    'ᴅ': 'd',\n",
        "    'ᴇ': 'e',\n",
        "    'ᴊ': 'j',\n",
        "    'ᴋ': 'k',\n",
        "    'ᴍ': 'm',\n",
        "    'ᴏ': 'o',\n",
        "    'ᴘ': 'p',\n",
        "    'ᴛ': 't',\n",
        "    'ᴜ': 'u',\n",
        "    '⁰': '0',\n",
        "    '⁴': '4',\n",
        "    '⁵': '5'\n",
        "}\n",
        "\n",
        "\n",
        "    def normalize_text(text: str) -> str:\n",
        "        out = []\n",
        "        for ch in text:\n",
        "        # skip unwanted characters\n",
        "            if ch in final_clean:\n",
        "               continue\n",
        "\n",
        "        # keep only allowed characters (latin, cyrillic, digits, spaces)\n",
        "            if not allowed_re.fullmatch(ch):\n",
        "               continue\n",
        "\n",
        "        # map special latin → uzbek letters\n",
        "            out.append(latin_map.get(ch, ch))\n",
        "\n",
        "        return \"\".join(out)\n",
        "\n",
        "\n",
        "    df['clean_text'] = df[\"normalized_review_text\"].astype(str).swifter.apply(normalize_text)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_token_data():\n",
        "    \"\"\"\n",
        "    Trains a BPE tokenizer on the text column, encodes + pads the texts\n",
        "    :returns: X (tensor), y (tensor), tokenizer (trained)\n",
        "    \"\"\"\n",
        "\n",
        "    uzum_df = normalize_uzum_reviews(uzum_reviews_filtered_df)\n",
        "\n",
        "\n",
        "    tokenizer = Tokenizer(models.BPE())\n",
        "    tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()\n",
        "\n",
        "\n",
        "    trainer = trainers.BpeTrainer(\n",
        "        vocab_size=vocab_size,\n",
        "        special_tokens=[\"<pad>\", \"<unk>\"]\n",
        "    )\n",
        "\n",
        "\n",
        "    tokenizer.train_from_iterator(uzum_df[text_column].astype(str).tolist(), trainer)\n",
        "\n",
        "    PAD_ID = tokenizer.token_to_id(\"<pad>\")\n",
        "    UNK_ID = tokenizer.token_to_id(\"<unk>\")\n",
        "\n",
        "\n",
        "    def padding_sentence(ids, max_len=block_size, pad_id=PAD_ID):\n",
        "        if len(ids) < max_len:\n",
        "            ids += [pad_id] * (max_len - len(ids))\n",
        "        return ids[:max_len]\n",
        "\n",
        "\n",
        "    X_seq = [padding_sentence(tokenizer.encode(str(t)).ids) for t in uzum_df[text_column]]\n",
        "\n",
        "\n",
        "    X = torch.tensor(X_seq, dtype=torch.long)\n",
        "    y = torch.tensor(uzum_df[target_column].values, dtype=torch.long)\n",
        "\n",
        "    return X, y, tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "1Q_fkprGGqsz"
      },
      "outputs": [],
      "source": [
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "\n",
        "        k = self.key(x)           # (B,T,hs)\n",
        "        q = self.query(x)         # (B,T,hs)\n",
        "\n",
        "        wei = q @ k.transpose(-2, -1) * C**-0.5\n",
        "        wei = F.softmax(wei, dim=-1)\n",
        "        wei = self.dropout(wei)\n",
        "\n",
        "        v = self.value(x)\n",
        "        out = wei @ v\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList(SelfAttention(head_size) for _ in range(num_heads))\n",
        "        self.proj = nn.Linear(n_embd, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4*n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffw = FeedForward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        x = x + self.ffw(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class EncoderTransformerClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, n_embd, n_head, n_layer, block_size, n_classes):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd)\n",
        "        self.classifier = nn.Linear(n_embd, n_classes)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        idx = idx.to(self.token_embedding_table.weight.device)\n",
        "        B, T = idx.shape\n",
        "\n",
        "        tok_emb = self.token_embedding_table(idx)\n",
        "        pos = torch.arange(T, device=idx.device)\n",
        "        pos_emb = self.position_embedding_table(pos)\n",
        "        x = tok_emb + pos_emb\n",
        "\n",
        "        x = self.blocks(x)\n",
        "        x = self.ln_f(x)\n",
        "        x_cls = x.mean(dim=1)\n",
        "\n",
        "        logits = self.classifier(x_cls)\n",
        "\n",
        "        if targets is None:\n",
        "            return logits\n",
        "\n",
        "        loss = F.cross_entropy(logits, targets)\n",
        "        return logits, loss\n",
        "\n",
        "\n",
        "    def predict(self, text, tokenizer):\n",
        "        self.eval()\n",
        "\n",
        "        ids = tokenizer.encode(text).ids\n",
        "        if len(ids) < block_size:\n",
        "            ids += [0] * (block_size - len(ids))\n",
        "        ids = ids[:block_size]\n",
        "\n",
        "        x = torch.tensor([ids], dtype=torch.long)\n",
        "        x = x.to(next(self.parameters()).device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = self(x)\n",
        "            probs = F.softmax(logits, dim=1)\n",
        "\n",
        "        return probs.cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "76cba7ef8fdf453484c850ec0be18e04",
            "37008f32b30845bd99fe288d41305b42",
            "e32fb1c348be4308b533c53411bf9ebb",
            "5e00350254a64af0a1004feaa5e0b677",
            "4ad047538b0149778fefd41052b398c1",
            "5ef7a0ae1f3e4040b2c2e9bc7abc89ff",
            "e68713e059214a2893d49fe3684a7237",
            "5cc1e7f04cf740a5bc30f0f5687fcba1",
            "020cd5642b5e4eac946533256ac08f97",
            "b03f92d38eff4b1bb424c29d51726dea",
            "a1882f9bd5b54974a58b089f8a29d571"
          ]
        },
        "id": "YEUkYK-jGqu5",
        "outputId": "94864497-b830-4588-d374-29cd36ac2cb8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "76cba7ef8fdf453484c850ec0be18e04",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Pandas Apply:   0%|          | 0/310217 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# getting data in proper format\n",
        "X, y, tokenizer = get_token_data()\n",
        "\n",
        "dataset = TensorDataset(X, y)\n",
        "loader = DataLoader(dataset, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iu0KSn_ZJb7X",
        "outputId": "5da4012c-3dd9-4874-e855-f4fc4178dcc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "-8h0CZK5Gz2C"
      },
      "outputs": [],
      "source": [
        "model = EncoderTransformerClassifier(\n",
        "    vocab_size=vocab_size,\n",
        "    n_embd=n_embd,\n",
        "    n_head=n_head,\n",
        "    n_layer=n_layer,\n",
        "    block_size=block_size,\n",
        "    n_classes=3\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "S04V0uCLGz4U"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKkCx9AYGz6Z",
        "outputId": "2781cf8d-b65f-425b-9bf0-4a15a127c42e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: loss = 0.3405\n",
            "Epoch 2: loss = 0.2875\n",
            "Epoch 3: loss = 0.2676\n",
            "Epoch 4: loss = 0.2510\n",
            "Epoch 5: loss = 0.2367\n",
            "Epoch 6: loss = 0.2232\n",
            "Epoch 7: loss = 0.2110\n",
            "Epoch 8: loss = 0.2021\n",
            "Epoch 9: loss = 0.1942\n",
            "Epoch 10: loss = 0.1891\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(max_iter):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for xb, yb in loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "\n",
        "        logits, loss = model(xb, yb)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}: loss = {total_loss/len(loader):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Am0-y8n-App8",
        "outputId": "e236283f-d725-473c-da94-76aa27808475"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding layer: 1920000\n",
            "Positional embedding: 5120\n",
            "Attention projections: 65792\n",
            "Feed-forward block: 132352\n",
            "Classifier: 195\n",
            "Total trainable parameters: 2123459\n"
          ]
        }
      ],
      "source": [
        "def count_module_params(module):\n",
        "    return sum(p.numel() for p in module.parameters() if p.requires_grad)\n",
        "\n",
        "embedding_params = count_module_params(model.token_embedding_table)\n",
        "pos_embedding_params = count_module_params(model.position_embedding_table)\n",
        "classifier_params = count_module_params(model.classifier)\n",
        "\n",
        "attn_params = 0\n",
        "ffw_params = 0\n",
        "for block in model.blocks:\n",
        "    attn_params += count_module_params(block.sa)\n",
        "    ffw_params += count_module_params(block.ffw)\n",
        "\n",
        "print(f\"Embedding layer: {embedding_params}\")\n",
        "print(f\"Positional embedding: {pos_embedding_params}\")\n",
        "print(f\"Attention projections: {attn_params}\")\n",
        "print(f\"Feed-forward block: {ffw_params}\")\n",
        "print(f\"Classifier: {classifier_params}\")\n",
        "\n",
        "print(f\"Total trainable parameters: {embedding_params + pos_embedding_params + attn_params + ffw_params + classifier_params}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vC-2aTOBsrn",
        "outputId": "bccc7677-461c-4d65-f72d-6acf1e65bf28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.025554828345775604, 0.023999152705073357, 0.9504460096359253]\n",
            "excellent\n"
          ]
        }
      ],
      "source": [
        "probs = model.predict(\"manga yoqdi mol\", tokenizer)[0].tolist()\n",
        "\n",
        "out = np.argmax(probs)\n",
        "\n",
        "print(probs)\n",
        "print('excellent' if out == 2 else 'fair' if out == 1 else 'poor')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cQhrThHH5oI",
        "outputId": "d2859409-8e04-4651-f498-c9bca1ec5864"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9985438585281372, 0.0013105991529300809, 0.0001456287718610838]\n",
            "poor\n"
          ]
        }
      ],
      "source": [
        "probs = model.predict(\"vashe yo'qmadi, ujas\", tokenizer)[0].tolist()\n",
        "\n",
        "out = np.argmax(probs)\n",
        "\n",
        "print(probs)\n",
        "print('excellent' if out == 2 else 'fair' if out == 1 else 'poor')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzTSttT7X5os",
        "outputId": "6d1091a9-d4c0-4b02-a6e5-f1a38bc32c13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.7582697868347168, 0.12224224209785461, 0.11948801577091217]\n",
            "poor\n"
          ]
        }
      ],
      "source": [
        "probs = model.predict(\"chidasa bo'lad\", tokenizer)[0].tolist()\n",
        "\n",
        "out = np.argmax(probs)\n",
        "\n",
        "print(probs)\n",
        "print('excellent' if out == 2 else 'fair' if out == 1 else 'poor')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "syWZq5f3QJZH"
      },
      "outputs": [],
      "source": [
        "# Save model state_dict\n",
        "torch.save(model.state_dict(), \"encoder_transformer_classifier.pth\")\n",
        "\n",
        "# Save tokenizer\n",
        "tokenizer.save(\"tokenizer.json\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqQ8Yku0RuBi",
        "outputId": "75ffd785-5ce8-4865-b0fc-b778b45d864c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.0003321970871184021, 5.523517756955698e-05, 0.9996126294136047]\n",
            "excellent\n"
          ]
        }
      ],
      "source": [
        "# Assuming model and tokenizer are loaded\n",
        "text = \"oyimga ko'rsattim bo'larkan, yoqmasa kerak deb o'ylagandim\"\n",
        "probs = model.predict(text, tokenizer)[0].tolist()\n",
        "\n",
        "out = np.argmax(probs)\n",
        "\n",
        "print(probs)\n",
        "print('excellent' if out == 2 else 'fair' if out == 1 else 'poor')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIk9APysZH6J",
        "outputId": "7eb4c655-30ae-4403-d3f4-f430f933ee3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9644067883491516, 0.0064508188515901566, 0.029142329469323158]\n",
            "poor\n"
          ]
        }
      ],
      "source": [
        "text = \"oyimga ko'rsattim bo'larkan, yoqmasa kerak deb o'ylagandim, lekin o'zimga to'grisi vashe ishlashi yoqmadi\"\n",
        "probs = model.predict(text, tokenizer)[0].tolist()\n",
        "\n",
        "out = np.argmax(probs)\n",
        "\n",
        "print(probs)\n",
        "print('excellent' if out == 2 else 'fair' if out == 1 else 'poor')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.14.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "020cd5642b5e4eac946533256ac08f97": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "37008f32b30845bd99fe288d41305b42": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ef7a0ae1f3e4040b2c2e9bc7abc89ff",
            "placeholder": "​",
            "style": "IPY_MODEL_e68713e059214a2893d49fe3684a7237",
            "value": "Pandas Apply: 100%"
          }
        },
        "4ad047538b0149778fefd41052b398c1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cc1e7f04cf740a5bc30f0f5687fcba1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e00350254a64af0a1004feaa5e0b677": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b03f92d38eff4b1bb424c29d51726dea",
            "placeholder": "​",
            "style": "IPY_MODEL_a1882f9bd5b54974a58b089f8a29d571",
            "value": " 310217/310217 [00:05&lt;00:00, 62209.50it/s]"
          }
        },
        "5ef7a0ae1f3e4040b2c2e9bc7abc89ff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76cba7ef8fdf453484c850ec0be18e04": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_37008f32b30845bd99fe288d41305b42",
              "IPY_MODEL_e32fb1c348be4308b533c53411bf9ebb",
              "IPY_MODEL_5e00350254a64af0a1004feaa5e0b677"
            ],
            "layout": "IPY_MODEL_4ad047538b0149778fefd41052b398c1"
          }
        },
        "a1882f9bd5b54974a58b089f8a29d571": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b03f92d38eff4b1bb424c29d51726dea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e32fb1c348be4308b533c53411bf9ebb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cc1e7f04cf740a5bc30f0f5687fcba1",
            "max": 310217,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_020cd5642b5e4eac946533256ac08f97",
            "value": 310217
          }
        },
        "e68713e059214a2893d49fe3684a7237": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
