{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghI5K0ZABa5B",
        "outputId": "9749784b-cba1-4c61-cb94-bb6f5687952b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using: cuda\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import regex as re\n",
        "import warnings\n",
        "import swifter\n",
        "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
        "from tokenizers import Tokenizer, models, pre_tokenizers, trainers\n",
        "\n",
        "\n",
        "\n",
        "# PARAMETERS OF MODEL\n",
        "block_size = 32\n",
        "n_embd = 128\n",
        "n_head = 4\n",
        "n_layer = 3\n",
        "dropout = 0.2\n",
        "batch_size = 64\n",
        "learning_rate = 2e-4\n",
        "vocab_size = 30_000\n",
        "\n",
        "max_iter = 5\n",
        "n_classes = 3\n",
        "\n",
        "# PADDING\n",
        "pad_token = '<pad>'\n",
        "unk_token = \"<unk>\"\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DATA NORMALIZATION\n",
        "def get_normalized_customer_reviews():\n",
        "    uzum_df = pd.read_parquet(\"./uzum_dataset.parquet\", engine='pyarrow')\n",
        "    rating_map = {\n",
        "    'poor' : 0,\n",
        "    'very poor' : 0,\n",
        "    'fair' : 1,\n",
        "    'good' : 2,\n",
        "    'excellent' : 2\n",
        "    }\n",
        "\n",
        "    uzum_df[\"rank\"] = uzum_df[\"rating\"].map(rating_map)\n",
        "    uzum_df.drop('rating', axis=1, inplace=True)\n",
        "\n",
        "    latin = r\"\\p{Latin}\"\n",
        "    cyrillic = r\"\\p{Cyrillic}\"\n",
        "    digits = r\"\\p{Number}\"\n",
        "\n",
        "\n",
        "    allowed_re = re.compile(fr\"(?:{latin}|{cyrillic}|{digits}|\\s)\")\n",
        "\n",
        "    final_clean = {'ø','ʔ','ʕ','ʖ','ᴥ','ᵕ','⅚','ᴗ'}\n",
        "\n",
        "    latin_map = {\n",
        "    \"à\": \"a\", \"á\": \"a\", \"â\": \"a\", \"ã\": \"a\",\n",
        "    \"ç\": \"c\",\n",
        "    \"è\": \"e\", \"é\": \"e\", \"ë\": \"e\",\n",
        "    \"ì\": \"i\", \"í\": \"i\",\n",
        "    \"ñ\": \"n\",\n",
        "    \"ò\": \"o\", \"ó\": \"o\", \"ô\": \"o\", \"õ\": \"o\", \"ö\": \"o\",\n",
        "    \"ù\": \"u\", \"ú\": \"u\", \"û\": \"u\", \"ü\": \"u\",\n",
        "    \"ý\": \"y\", \"ÿ\": \"y\",\n",
        "    \"ĝ\": \"g'\", \"ğ\": \"g'\", \"ġ\": \"g'\", \"ģ\": \"g'\",\n",
        "    \"ĥ\": \"h\",\n",
        "    \"ı\": \"i\",\n",
        "    \"ĵ\": \"j\",\n",
        "    \"ķ\": \"k\",\n",
        "    \"ĺ\": \"l\", \"ļ\": \"l\",\n",
        "    \"ń\": \"n\", \"ň\": \"n\",\n",
        "    \"ō\": \"o'\", \"ŏ\": \"o'\", \"ő\": \"o'\",\n",
        "    \"ŕ\": \"r\",\n",
        "    \"ś\": \"s\", \"ş\": \"sh\",\n",
        "    \"ũ\": \"u\", \"ū\": \"u\", \"ů\": \"u\",\n",
        "    \"ź\": \"z\", \"ž\": \"j\",\n",
        "    \"ǒ\": \"o'\", \"ǫ\": \"q\",\n",
        "    \"ǵ\": \"g'\",\n",
        "    \"ɓ\": \"b\",\n",
        "    \"ə\": \"e\",\n",
        "    '²': '2',\n",
        "    '³': '3',\n",
        "    '¹': '1',\n",
        "    'ď': 'd',\n",
        "    'ɢ': 'g',\n",
        "    'ɪ': 'i',\n",
        "    'ɴ': 'n',\n",
        "    'ʀ': 'r',\n",
        "    'ʏ': 'y',\n",
        "    'ʜ': 'h',\n",
        "    'ʟ': 'l',\n",
        "    'ө': 'o',\n",
        "    'ᴀ': 'a',\n",
        "    'ᴄ': 'c',\n",
        "    'ᴅ': 'd',\n",
        "    'ᴇ': 'e',\n",
        "    'ᴊ': 'j',\n",
        "    'ᴋ': 'k',\n",
        "    'ᴍ': 'm',\n",
        "    'ᴏ': 'o',\n",
        "    'ᴘ': 'p',\n",
        "    'ᴛ': 't',\n",
        "    'ᴜ': 'u',\n",
        "    '⁰': '0',\n",
        "    '⁴': '4',\n",
        "    '⁵': '5'\n",
        "}\n",
        "\n",
        "\n",
        "    def normalize_text(text: str) -> str:\n",
        "        out = []\n",
        "        for ch in text:\n",
        "            # skips unnessary ones\n",
        "            if ch in final_clean:\n",
        "               continue\n",
        "\n",
        "            # keeps only necessary chars\n",
        "            if not allowed_re.fullmatch(ch):\n",
        "               continue\n",
        "\n",
        "            # maps final\n",
        "            out.append(latin_map.get(ch, ch))\n",
        "\n",
        "        return \"\".join(out)\n",
        "\n",
        "    uzum_df[\"review_text\"] = uzum_df[\"normalized_review_text\"].astype(str).swifter.apply(normalize_text)\n",
        "    uzum_df['len'] = uzum_df['review_text'].astype(str).str.len()\n",
        "    uzum_df = uzum_df[uzum_df['len'] > 0].drop(['len', 'normalized_review_text'], axis=1)[['review_text', 'rank']]\n",
        "\n",
        "    return uzum_df\n",
        "\n",
        "\n",
        "\n",
        "def get_tokenized_data():\n",
        "\n",
        "  df = get_normalized_customer_reviews()\n",
        "\n",
        "  tokenizer = Tokenizer(models.BPE())\n",
        "  tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()\n",
        "\n",
        "\n",
        "  trainer = trainers.BpeTrainer(\n",
        "        vocab_size=vocab_size,\n",
        "        special_tokens=[pad_token, unk_token]\n",
        "    )\n",
        "\n",
        "  tokenizer.train_from_iterator(df[\"review_text\"].astype(str).tolist(), trainer)\n",
        "\n",
        "  PAD_ID = tokenizer.token_to_id(pad_token)\n",
        "  UNK_ID = tokenizer.token_to_id(unk_token)\n",
        "\n",
        "  def encode_and_padding(text):\n",
        "    ids = tokenizer.encode(text).ids[:block_size]\n",
        "    ids += [PAD_ID] * (block_size - len(ids))\n",
        "    return ids\n",
        "\n",
        "\n",
        "  X_padded = [encode_and_padding(t) for t in df[\"review_text\"]]\n",
        "\n",
        "  data = torch.tensor(X_padded, dtype=torch.long)\n",
        "  targets = torch.tensor(df['rank'].values, dtype=torch.long)\n",
        "\n",
        "  return data, targets, tokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TRANSFORMER MODEL\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "\n",
        "        k = self.key(x)           # (B,T,hs)\n",
        "        q = self.query(x)         # (B,T,hs)\n",
        "\n",
        "        wei = q @ k.transpose(-2, -1) * (k.size(-1)**-0.5)\n",
        "        wei = F.softmax(wei, dim=-1)\n",
        "        wei = self.dropout(wei)\n",
        "\n",
        "        v = self.value(x)\n",
        "        out = wei @ v\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList(SelfAttention(head_size) for _ in range(num_heads))\n",
        "        self.proj = nn.Linear(n_embd, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(4*n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffw = FeedForward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        x = x + self.ffw(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "class EncoderTransformerClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd)\n",
        "        self.classifier = nn.Linear(n_embd, n_classes)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        idx = idx.to(self.token_embedding_table.weight.device)\n",
        "        B, T = idx.shape\n",
        "\n",
        "        tok_emb = self.token_embedding_table(idx)\n",
        "        pos = torch.arange(T, device=idx.device)\n",
        "        pos_emb = self.position_embedding_table(pos)\n",
        "        x = tok_emb + pos_emb\n",
        "\n",
        "        x = self.blocks(x)\n",
        "        x = self.ln_f(x)\n",
        "        lengths = (idx != 0).sum(dim=1) - 1\n",
        "        x_cls = x[torch.arange(B), lengths]\n",
        "\n",
        "        logits = self.classifier(x_cls)\n",
        "\n",
        "        if targets is None:\n",
        "            return logits\n",
        "\n",
        "        loss = F.cross_entropy(logits, targets)\n",
        "        return logits, loss\n",
        "\n",
        "\n",
        "    def predict(self, text, tokenizer):\n",
        "        self.eval()\n",
        "\n",
        "        ids = tokenizer.encode(text).ids\n",
        "        if len(ids) < block_size:\n",
        "            ids += [0] * (block_size - len(ids))\n",
        "        ids = ids[:block_size]\n",
        "\n",
        "        x = torch.tensor([ids], dtype=torch.long)\n",
        "        x = x.to(next(self.parameters()).device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = self(x)\n",
        "            probs = F.softmax(logits, dim=1)\n",
        "\n",
        "        return probs.cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# getting data in proper format\n",
        "data, targets, tokenizer = get_tokenized_data()\n",
        "\n",
        "train_size = int(len(data) * 0.9)\n",
        "val_size = len(data) - train_size\n",
        "\n",
        "dataset = TensorDataset(data, targets)\n",
        "train_data, val_data = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "val_loader   = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# building the model\n",
        "model = EncoderTransformerClassifier().to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "c0f5e253b2c84acc9076e6c241a4252c",
            "93e9754a16e346589d5a860462ad756b",
            "b26f1e8dbc46434ba56946bd003d11f4",
            "b09371a9013842d295598955e0f8df5f",
            "d1fbdbdf6cf54c95bce44ed03ab5b94b",
            "484536f225dd4010b3888b391eab1bac",
            "4e897f94713a42ddb5932426b4d5408d",
            "39b3821d17be415d874fbaac537b6718",
            "ffd74b44978c4a769dac71c9d3c1f281",
            "84ec2d789c8f44438d10d96917443b56",
            "affe9fd73b0f4ebeac215327112c8035"
          ]
        },
        "id": "8yde1xfpBd8C",
        "outputId": "6dfe3d8b-fae2-46d5-a4b7-c53a473e30df"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c0f5e253b2c84acc9076e6c241a4252c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Pandas Apply:   0%|          | 0/352151 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch [1/5] train loss: 0.3890 val loss: 0.3489 val acc: 0.8811\n",
            "epoch [2/5] train loss: 0.3278 val loss: 0.3296 val acc: 0.8881\n",
            "epoch [3/5] train loss: 0.3086 val loss: 0.3241 val acc: 0.8919\n",
            "epoch [4/5] train loss: 0.2943 val loss: 0.3212 val acc: 0.8932\n",
            "epoch [5/5] train loss: 0.2832 val loss: 0.3214 val acc: 0.8947\n"
          ]
        }
      ],
      "source": [
        "# training loop\n",
        "for epoch in range(max_iter):\n",
        "\n",
        "    # train\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "\n",
        "    for xb, yb in train_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits, loss = model(xb, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    train_loss /= len(train_loader)\n",
        "\n",
        "    # validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in val_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "\n",
        "            logits, loss = model(xb, yb)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            preds = logits.argmax(dim=1)\n",
        "            correct += (preds == yb).sum().item()\n",
        "            total += yb.size(0)\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "    val_acc = correct / total\n",
        "\n",
        "    print(f\"epoch [{epoch+1}/{max_iter}] \"\n",
        "      f\"train loss: {train_loss:.4f} \"\n",
        "      f\"val loss: {val_loss:.4f} \"\n",
        "      f\"val acc: {val_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6xskaE9GhCc",
        "outputId": "a270945a-0479-43c5-dfaf-73abd2dddede"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.14750970900058746, 0.06039566546678543, 0.7920945882797241]\n",
            "postive\n"
          ]
        }
      ],
      "source": [
        "# testing 1\n",
        "text = \"oyimga ko'rsattim bo'lar ekan, yoqmasa kerak deb o'ylagandim\"\n",
        "probs = model.predict(text, tokenizer)[0].tolist()\n",
        "out = np.argmax(probs)\n",
        "print(probs)\n",
        "print('postive' if out == 2 else 'neutral' if out == 1 else 'negative')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FL4tdaKqGh3y",
        "outputId": "070c56b3-039b-422f-ee77-ac51e2a39ef0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.8540540933609009, 0.109282948076725, 0.036662884056568146]\n",
            "negative\n"
          ]
        }
      ],
      "source": [
        "# testing 2\n",
        "text2 = \"oyimga ko'rsattim bo'lar ekan, yoqmasa kerak deb o'ylagandim, lekin o'zimga to'grisi vashe ishlashi yoqmadi\"\n",
        "probs2 = model.predict(text2, tokenizer)[0].tolist()\n",
        "out2 = np.argmax(probs2)\n",
        "print(probs2)\n",
        "print('postive' if out2 == 2 else 'neutral' if out2 == 1 else 'negative')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7CPRgjFGlUV",
        "outputId": "22469597-9f52-481a-8533-f2dfce337f86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.5298020839691162, 0.19840247929096222, 0.271795392036438]\n",
            "negative\n"
          ]
        }
      ],
      "source": [
        "# testing 3\n",
        "text3 = \"telefon boshida yaxsh ishladi, keyin o'zidan o'zi ekrani ishlamiy qoldi\"\n",
        "probs3 = model.predict(text3, tokenizer)[0].tolist()\n",
        "out3 = np.argmax(probs3)\n",
        "print(probs3)\n",
        "print('postive' if out3 == 2 else 'neutral' if out3 == 1 else 'negative')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFQhxtkkGnIt",
        "outputId": "bcf61928-cbce-49c3-be32-9216d9b39311"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.548626720905304, 0.2190316766500473, 0.23234164714813232]\n",
            "negative\n"
          ]
        }
      ],
      "source": [
        "# testing 4\n",
        "text3 = \"sotuvchiga bog'lanib bomayapti, texnikasi yaxsh chiqmadi\"\n",
        "probs3 = model.predict(text3, tokenizer)[0].tolist()\n",
        "out3 = np.argmax(probs3)\n",
        "print(probs3)\n",
        "print('postive' if out3 == 2 else 'neutral' if out3 == 1 else 'negative')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vmiWTQ2GpHk",
        "outputId": "4eba6241-9d5a-4c6a-f399-bd650e031613"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.4478980004787445, 0.2135918289422989, 0.3385101854801178]\n",
            "negative\n"
          ]
        }
      ],
      "source": [
        "# testing 5\n",
        "text3 = \"boshida yaxsh ishladi, keyin buzilib qoldi\"\n",
        "probs3 = model.predict(text3, tokenizer)[0].tolist()\n",
        "out3 = np.argmax(probs3)\n",
        "print(probs3)\n",
        "print('postive' if out3 == 2 else 'neutral' if out3 == 1 else 'negative')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jd2-QApeHbFd",
        "outputId": "761032f6-6b6d-45c5-a948-3abc44d1f59e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding layer: 3840000\n",
            "Positional embedding: 4096\n",
            "Attention projections: 196992\n",
            "Feed-forward block: 395136\n",
            "Classifier: 387\n",
            "Total trainable parameters: 4436611\n"
          ]
        }
      ],
      "source": [
        "def count_module_params(module):\n",
        "    return sum(p.numel() for p in module.parameters() if p.requires_grad)\n",
        "\n",
        "embedding_params = count_module_params(model.token_embedding_table)\n",
        "pos_embedding_params = count_module_params(model.position_embedding_table)\n",
        "classifier_params = count_module_params(model.classifier)\n",
        "\n",
        "attn_params = 0\n",
        "ffw_params = 0\n",
        "for block in model.blocks:\n",
        "    attn_params += count_module_params(block.sa)\n",
        "    ffw_params += count_module_params(block.ffw)\n",
        "\n",
        "print(f\"Embedding layer: {embedding_params}\")\n",
        "print(f\"Positional embedding: {pos_embedding_params}\")\n",
        "print(f\"Attention projections: {attn_params}\")\n",
        "print(f\"Feed-forward block: {ffw_params}\")\n",
        "print(f\"Classifier: {classifier_params}\")\n",
        "\n",
        "print(f\"Total trainable parameters: {embedding_params + pos_embedding_params + attn_params + ffw_params + classifier_params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "xG14IXKmHfPj"
      },
      "outputs": [],
      "source": [
        "# SAVING MODEL AND TOKENIZER\n",
        "torch.save(model.state_dict(), \"encoder_transformer_classifier.pth\")\n",
        "tokenizer.save(\"tokenizer.json\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "39b3821d17be415d874fbaac537b6718": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "484536f225dd4010b3888b391eab1bac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e897f94713a42ddb5932426b4d5408d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84ec2d789c8f44438d10d96917443b56": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93e9754a16e346589d5a860462ad756b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_484536f225dd4010b3888b391eab1bac",
            "placeholder": "​",
            "style": "IPY_MODEL_4e897f94713a42ddb5932426b4d5408d",
            "value": "Pandas Apply: 100%"
          }
        },
        "affe9fd73b0f4ebeac215327112c8035": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b09371a9013842d295598955e0f8df5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84ec2d789c8f44438d10d96917443b56",
            "placeholder": "​",
            "style": "IPY_MODEL_affe9fd73b0f4ebeac215327112c8035",
            "value": " 352151/352151 [00:08&lt;00:00, 43021.15it/s]"
          }
        },
        "b26f1e8dbc46434ba56946bd003d11f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39b3821d17be415d874fbaac537b6718",
            "max": 352151,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ffd74b44978c4a769dac71c9d3c1f281",
            "value": 352151
          }
        },
        "c0f5e253b2c84acc9076e6c241a4252c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_93e9754a16e346589d5a860462ad756b",
              "IPY_MODEL_b26f1e8dbc46434ba56946bd003d11f4",
              "IPY_MODEL_b09371a9013842d295598955e0f8df5f"
            ],
            "layout": "IPY_MODEL_d1fbdbdf6cf54c95bce44ed03ab5b94b"
          }
        },
        "d1fbdbdf6cf54c95bce44ed03ab5b94b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffd74b44978c4a769dac71c9d3c1f281": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
